{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa317a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install unrar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f875c696",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unrar x /content/colab.rar /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b19a52c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator, img_to_array, load_img\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, ImageEnhance, ImageOps, ImageFilter\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\saleh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\__init__.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32mc:\\Users\\saleh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m feature_column\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m graph_util\n",
      "File \u001b[1;32mc:\\Users\\saleh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\feature_column\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.feature_column namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column_v2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DenseColumn \u001b[38;5;66;03m# line: 1777\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column_v2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FeatureTransformationCache \u001b[38;5;66;03m# line: 1962\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column_v2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SequenceDenseColumn \u001b[38;5;66;03m# line: 1941\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\saleh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m readers\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m feature_column \u001b[38;5;28;01mas\u001b[39;00m fc_old\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m feature_column_v2_types \u001b[38;5;28;01mas\u001b[39;00m fc_types\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m serialization\n",
      "File \u001b[1;32mc:\\Users\\saleh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sparse_tensor \u001b[38;5;28;01mas\u001b[39;00m sparse_tensor_lib\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m base\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_ops\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_ops_stack\n",
      "File \u001b[1;32mc:\\Users\\saleh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\layers\\base.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Contains the base Layer class, from which all layers inherit.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy_tf_layers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m base\n\u001b[0;32m     18\u001b[0m InputSpec \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mInputSpec\n\u001b[0;32m     20\u001b[0m keras_style_scope \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mkeras_style_scope\n",
      "File \u001b[1;32mc:\\Users\\saleh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\keras\\__init__.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mc:\\Users\\saleh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\keras\\models.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sequential\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m training\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m training_v1\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_layer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AddMetric\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_layer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Layer\n",
      "File \u001b[1;32mc:\\Users\\saleh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m base_layer\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m training \u001b[38;5;28;01mas\u001b[39;00m training_lib\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m training_arrays_v1\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m training_distributed_v1\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m training_eager_v1\n",
      "File \u001b[1;32mc:\\Users\\saleh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nest\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 37\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m issparse  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m   issparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\saleh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\__init__.py:315\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_index_dtype, safely_cast_index_arrays\n\u001b[0;32m    314\u001b[0m \u001b[38;5;66;03m# For backward compatibility with v0.19.\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csgraph\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    319\u001b[0m     base, bsr, compressed, construct, coo, csc, csr, data, dia, dok, extract,\n\u001b[0;32m    320\u001b[0m     lil, sparsetools, sputils\n\u001b[0;32m    321\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\saleh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\csgraph\\__init__.py:198\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_min_spanning_tree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m minimum_spanning_tree\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_flow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m maximum_flow\n\u001b[1;32m--> 198\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matching\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    199\u001b[0m     maximum_bipartite_matching, min_weight_full_bipartite_matching\n\u001b[0;32m    200\u001b[0m )\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_reordering\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m reverse_cuthill_mckee, structural_rank\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    203\u001b[0m     construct_dist_matrix, reconstruct_path, csgraph_from_dense,\n\u001b[0;32m    204\u001b[0m     csgraph_to_dense, csgraph_masked_from_dense, csgraph_from_masked,\n\u001b[0;32m    205\u001b[0m     csgraph_to_masked\n\u001b[0;32m    206\u001b[0m )\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:645\u001b[0m, in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Data Augmenation\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from PIL import Image, ImageEnhance, ImageOps, ImageFilter\n",
    "import random\n",
    "\n",
    "# Paths for directories\n",
    "aug_train_dir = '/content/colab/Train/Train/Augmented'\n",
    "aug_test_dir = '/content/colab/Test/Test/Augmented'\n",
    "\n",
    "# Subfolders corresponding to the classes\n",
    "subfolders = ['BG', 'N', 'D', 'P', 'V', 'S']\n",
    "\n",
    "# Original dataset size\n",
    "train_counts = {'BG': 75, 'D': 139, 'N': 75, 'P': 100, 'S': 122, 'V': 185}\n",
    "test_counts = {'BG': 25, 'D': 46, 'N': 25, 'P': 34, 'S': 42, 'V': 62}\n",
    "\n",
    "# Target counts for augmentation\n",
    "train_target_count = 1500  # Target count for training set\n",
    "test_target_count = 500    # Target count for test set\n",
    "\n",
    "# Function to create augmentation folders\n",
    "def create_aug_folders(base_dir):\n",
    "    for subfolder in subfolders:\n",
    "        aug_folder_path = os.path.join(base_dir, subfolder)\n",
    "        os.makedirs(aug_folder_path, exist_ok=True)\n",
    "\n",
    "# Create folders for augmented images\n",
    "create_aug_folders(aug_train_dir)\n",
    "create_aug_folders(aug_test_dir)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2\n",
    ")\n",
    "\n",
    "def augment_image(image):\n",
    "    augmented_images = []\n",
    "    # Horizontal and Vertical Flips\n",
    "    augmented_images.append(ImageOps.mirror(image))  # Horizontal flip\n",
    "    augmented_images.append(ImageOps.flip(image))  # Vertical flip\n",
    "    # Vertical-Horizontal Flip\n",
    "    augmented_images.append(ImageOps.mirror(ImageOps.flip(image)))\n",
    "    # Gaussian Blur\n",
    "    augmented_images.append(image.filter(ImageFilter.GaussianBlur(radius=2)))\n",
    "    # Gaussian Noise\n",
    "    noise = np.random.normal(0, 25, (image.size[1], image.size[0], 3)).astype(np.uint8)\n",
    "    noisy_image = np.array(image) + noise\n",
    "    augmented_images.append(Image.fromarray(np.clip(noisy_image, 0, 255).astype(np.uint8)))\n",
    "    # Gamma Correction\n",
    "    gamma_corrected = ImageEnhance.Brightness(image).enhance(1.5)\n",
    "    augmented_images.append(gamma_corrected)\n",
    "    # Equalize Histogram\n",
    "    equalized_image = ImageOps.equalize(image)\n",
    "    augmented_images.append(equalized_image)\n",
    "    # Increase Saturation, Hue, Red, Green, Blue\n",
    "    augmented_images.append(ImageEnhance.Color(image).enhance(1.5))  # Saturation\n",
    "    # Adjust RGB channels\n",
    "    for i, factor in enumerate([1.2, 1.1, 1.3]):\n",
    "        channels = list(image.split())\n",
    "        channels[i] = ImageEnhance.Brightness(channels[i]).enhance(factor)\n",
    "        augmented_images.append(Image.merge(image.mode, channels))\n",
    "    return augmented_images\n",
    "\n",
    "# Function to apply augmentations and save\n",
    "def apply_augmentations(image_path, save_dir, num_augmentations):\n",
    "    # Load image\n",
    "    img = load_img(image_path)\n",
    "    img_array = img_to_array(img)\n",
    "    generated_count = 0\n",
    "\n",
    "    # Generate augmented images with ImageDataGenerator\n",
    "    img_batch = np.expand_dims(img_array, axis=0)\n",
    "    for batch in datagen.flow(img_batch, batch_size=1):\n",
    "        aug_img = batch[0].astype(np.uint8)\n",
    "        aug_img = Image.fromarray(aug_img)\n",
    "        aug_img.save(os.path.join(save_dir, f\"aug_{generated_count}_{os.path.basename(image_path)}\"))\n",
    "        generated_count += 1\n",
    "        if generated_count >= num_augmentations:\n",
    "            break\n",
    "\n",
    "    if generated_count < num_augmentations:\n",
    "        # Apply custom augmentations\n",
    "        custom_augmented_images = augment_image(img)\n",
    "        for aug_img in custom_augmented_images:\n",
    "            if generated_count >= num_augmentations:\n",
    "                break\n",
    "            aug_img.save(os.path.join(save_dir, f\"custom_aug_{generated_count}_{os.path.basename(image_path)}\"))\n",
    "            generated_count += 1\n",
    "\n",
    "# Function to augment dataset\n",
    "def augment_dataset(original_dir, aug_dir, counts, target_count):\n",
    "    for subfolder in subfolders:\n",
    "        folder_path = os.path.join(original_dir, subfolder)\n",
    "        save_path = os.path.join(aug_dir, subfolder)\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        current_count = counts[subfolder]\n",
    "        num_to_generate = target_count - current_count\n",
    "\n",
    "        if num_to_generate <= 0:\n",
    "            continue\n",
    "\n",
    "        images = [f for f in os.listdir(folder_path) if f.endswith(('jpg', 'jpeg', 'png'))]\n",
    "        random.shuffle(images)\n",
    "\n",
    "        for img_file in images:\n",
    "            img_path = os.path.join(folder_path, img_file)\n",
    "            apply_augmentations(img_path, save_path, num_to_generate // len(images))\n",
    "            print(f\"Augmented {img_file} from {subfolder} and saved to {save_path}\")\n",
    "\n",
    "        # Fill remaining images if needed\n",
    "        remaining = target_count - len(os.listdir(save_path))\n",
    "        while remaining > 0:\n",
    "            for img_file in images:\n",
    "                if remaining <= 0:\n",
    "                    break\n",
    "                img_path = os.path.join(folder_path, img_file)\n",
    "                apply_augmentations(img_path, save_path, 1)\n",
    "                remaining -= 1\n",
    "\n",
    "# Augment train and test data\n",
    "augment_dataset(\n",
    "    '/content/colab/Train/Train',\n",
    "    aug_train_dir,\n",
    "    train_counts,\n",
    "    train_target_count\n",
    ")\n",
    "\n",
    "augment_dataset(\n",
    "    '/content/colab/Test/Test',\n",
    "    aug_test_dir,\n",
    "    test_counts,\n",
    "    test_target_count\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c72afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG19\n",
    "\n",
    "mport os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Paths to your train and test directories\n",
    "train_dir = '/content/colab/Train/Train/Augmented'\n",
    "test_dir = '/content/colab/Test/Test/Augmented'\n",
    "\n",
    "\n",
    "# Image dimensions and batch size\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Normalizing the training and test datasets\n",
    "datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "\n",
    "# Creating data generators\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Load the VGG19 model with pre-trained weights from ImageNet\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "# Freezing the base model layers to retain pre-trained weights\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Adding custom layers on top of the base model\n",
    "# x = base_model.output\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
    "\n",
    "# x = base_model.output\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(256, activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Adding L2 regularization to Dense layers\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)  # Add L2 here\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)  # Add L2 here\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "\n",
    "predictions = Dense(6, activation='softmax')(x)\n",
    "\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks: ModelCheckpoint and EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"best_vgg19_model.keras\", save_best_only=True, monitor=\"val_loss\", mode=\"min\", verbose=1)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Check if a saved model exists and resume training if available\n",
    "if os.path.exists(\"/content/best_vgg19_model.keras\"):\n",
    "    # Load the saved model\n",
    "    model = tf.keras.models.load_model(\"best_vgg19_model.keras\")\n",
    "    print(\"Model loaded from checkpoint.\")\n",
    "else:\n",
    "    print(\"No saved model found, starting from scratch.\")\n",
    "\n",
    "# Train the model\n",
    "EPOCHS = 20\n",
    "\n",
    "steps_per_epoch = len(train_generator)\n",
    "validation_steps = len(test_generator)\n",
    "print(steps_per_epoch)\n",
    "print(validation_steps)\n",
    "\n",
    "# Callbacks: ReduceLROnPlateau, ModelCheckpoint, and EarlyStopping\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',   # Metric to monitor\n",
    "    factor=0.5,           # Reduce learning rate by a factor of 0.5\n",
    "    patience=3,           # Wait for 3 epochs of no improvement\n",
    "    min_lr=1e-6,          # Minimum learning rate\n",
    "    verbose=1             # Print updates\n",
    ")\n",
    "\n",
    "# Callbacks list\n",
    "callbacks = [checkpoint, early_stopping, reduce_lr]\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print(f\"Test Accuracy (initial): {test_acc:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fine-tuning: Unfreeze some of the top layers of the base model\n",
    "for layer in base_model.layers[-12:]:  # Adjust the number of layers to unfreeze\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile the model with a lower learning rate for fine-tuning\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Additional training for fine-tuning\n",
    "fine_tune_epochs = 10\n",
    "total_epochs = EPOCHS + fine_tune_epochs\n",
    "\n",
    "fine_tune_history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    validation_data=test_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print(f\"Test Accuracy after fine-tuning: {test_acc:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Save the model\n",
    "# model.save(\"vgg19_finetuned_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe0237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#densenet201\n",
    "\n",
    "import os\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Path to your augmented dataset\n",
    "train_dir = '/content/colab/Train/Train/Augmented'\n",
    "val_dir = '/content/colab/Test/Test/Augmented'\n",
    "\n",
    "# Image data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),  # Input size for DenseNet201\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),  # Input size for DenseNet201\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Build DenseNet201 Model\n",
    "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)  # Adjust output classes\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('densenet201_footulcer.h5')\n",
    "\n",
    "print(\"Model training completed and saved as 'densenet201_footulcer.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2238bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mobilenetv2\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# Enable mixed precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Paths to your train and test directories\n",
    "train_dir = '/content/colab/Train/Train/Augmented'\n",
    "test_dir = '/content/colab/Test/Test/Augmented'\n",
    "\n",
    "# Image dimensions and batch size\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Data augmentation for training and normalization for testing\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# Data generators\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Load the MobileNetV2 base model\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Custom classification head with BatchNormalization and L2 regularization\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks: ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "checkpoint = ModelCheckpoint(\"best_mobilenet_model.keras\", save_best_only=True, monitor=\"val_loss\", mode=\"min\", verbose=1)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "\n",
    "# Check for saved model\n",
    "if os.path.exists(\"best_mobilenet_model.keras\"):\n",
    "    model = tf.keras.models.load_model(\"best_mobilenet_model.keras\")\n",
    "    print(\"Model loaded from checkpoint.\")\n",
    "else:\n",
    "    print(\"No saved model found, starting from scratch.\")\n",
    "\n",
    "# Train the model\n",
    "EPOCHS = 20\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print(f\"Test Accuracy (initial): {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05061b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NasNet\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import NASNetMobile\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import os\n",
    "\n",
    "# Paths to your dataset\n",
    "train_dir = '/content/colab/Train/Train/Augmented'\n",
    "test_dir = '/content/colab/Test/Test/Augmented'\n",
    "\n",
    "# Paths for saving the model\n",
    "model_path = 'best_model.keras'\n",
    "\n",
    "# Parameters\n",
    "img_size = 224  # NASNetMobile requires 224x224 input\n",
    "batch_size = 32\n",
    "num_classes = 6\n",
    "epochs = 10\n",
    "\n",
    "# Data Augmentation and Loading\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Check if a pre-trained model exists\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Loading existing model...\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "else:\n",
    "    # Load Pretrained NASNetMobile\n",
    "    base_model = NASNetMobile(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "    # Freeze the base model\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Add custom layers with Dropout and L2 Regularization\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)  # Global average pooling to reduce dimensions\n",
    "    x = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(x)  # L2 regularization\n",
    "    x = Dropout(0.5)(x)  # Dropout layer\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)  # Final output layer\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Callbacks: ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Save the final model\n",
    "model.save('nasnet_transfer_learning_final_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfd0598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evalutation results (run for each saved model)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Path to your validation dataset\n",
    "val_dir = '/content/colab/Test/Test/Augmented'\n",
    "\n",
    "# Load validation data\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),  # DenseNet201 default input size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Ensure no shuffling for proper evaluation\n",
    ")\n",
    "\n",
    "def evaluate_and_visualize(model_path, data_generator):\n",
    "    \"\"\"\n",
    "    Evaluates and visualizes the DenseNet201 model's performance.\n",
    "\n",
    "    Parameters:\n",
    "    - model_path (str): Path to the saved DenseNet201 model.\n",
    "    - data_generator: The ImageDataGenerator for the test/validation data.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with accuracy, precision, recall, and F1-score.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the saved DenseNet201 model\n",
    "        model = load_model(model_path)\n",
    "\n",
    "        # Get true labels and predict probabilities\n",
    "        y_true = data_generator.classes  # True class labels\n",
    "        y_pred_prob = model.predict(data_generator, verbose=1)  # Predicted probabilities\n",
    "\n",
    "        # Convert probabilities to predicted class indices\n",
    "        y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, average='macro')\n",
    "        recall = recall_score(y_true, y_pred, average='macro')\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "        # Classification report\n",
    "        print(\"Classification Report:\\n\", classification_report(y_true, y_pred, target_names=list(data_generator.class_indices.keys())))\n",
    "\n",
    "        # Visualize metrics\n",
    "        metrics = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1-score\": f1}\n",
    "        visualize_metrics(metrics)\n",
    "\n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        visualize_confusion_matrix(cm, data_generator.class_indices.keys())\n",
    "\n",
    "        # ROC Curve\n",
    "        visualize_roc_curve(y_true, y_pred_prob, data_generator.class_indices.keys())\n",
    "\n",
    "        # Return the metrics\n",
    "        return metrics\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during evaluation: {e}\")\n",
    "        return None\n",
    "\n",
    "def visualize_metrics(metrics):\n",
    "    \"\"\"\n",
    "    Plots a bar chart for the provided metrics.\n",
    "\n",
    "    Parameters:\n",
    "    - metrics (dict): A dictionary with metric names as keys and values as scores.\n",
    "    \"\"\"\n",
    "    names = list(metrics.keys())\n",
    "    values = list(metrics.values())\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(names, values, color=['skyblue', 'orange', 'green', 'red'])\n",
    "    plt.ylim(0, 1)  # Assuming metrics are between 0 and 1\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Model Performance Metrics\")\n",
    "    for i, value in enumerate(values):\n",
    "        plt.text(i, value + 0.02, f\"{value:.2f}\", ha='center', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "def visualize_confusion_matrix(cm, class_labels):\n",
    "    \"\"\"\n",
    "    Visualizes the confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - cm (ndarray): The confusion matrix.\n",
    "    - class_labels: The list of class labels.\n",
    "    \"\"\"\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "    disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "def visualize_roc_curve(y_true, y_pred_prob, class_labels):\n",
    "    \"\"\"\n",
    "    Plots the ROC Curve for each class.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true (array): True class labels.\n",
    "    - y_pred_prob (array): Predicted probabilities.\n",
    "    - class_labels (list): List of class labels.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i, label in enumerate(class_labels):\n",
    "        fpr, tpr, _ = roc_curve(y_true == i, y_pred_prob[:, i])\n",
    "        auc = roc_auc_score(y_true == i, y_pred_prob[:, i])\n",
    "        plt.plot(fpr, tpr, label=f\"{label} (AUC = {auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Random chance line\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "model_path = 'best_model.keras'  # Update with your DenseNet201 model file path\n",
    "results = evaluate_and_visualize(model_path, val_generator)\n",
    "\n",
    "if results:\n",
    "    print(f\"Metrics:\")\n",
    "    for metric, value in results.items():\n",
    "        print(f\"{metric.capitalize()}: {value:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
